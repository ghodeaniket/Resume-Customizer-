# Resume Customizer Environment Variables
# Copy this file to .env.dev for development or .env.prod for production

#-----------------------------------------------
# Server Configuration
#-----------------------------------------------
NODE_ENV=development  # development, production
PORT=3000
PUBLIC_URL=http://localhost:3000

#-----------------------------------------------
# Database Configuration
#-----------------------------------------------
# For development, format: postgres://user:password@host:port/database
DATABASE_URL=postgres://postgres:postgres@postgres:5432/resume_customizer

# For production, these are used separately
DB_HOST=postgres
DB_PORT=5432
DB_NAME=resume_customizer
DB_USER=postgres
DB_PASSWORD=securepassword

#-----------------------------------------------
# Authentication
#-----------------------------------------------
JWT_SECRET=your-secret-key-here  # Change this to a secure value!
JWT_EXPIRES_IN=7d

#-----------------------------------------------
# Storage Configuration
#-----------------------------------------------
STORAGE_TYPE=s3  # s3, local

# S3/MinIO Configuration
S3_BUCKET=resume-customizer-bucket
S3_REGION=us-east-1
AWS_ACCESS_KEY_ID=minioadmin
AWS_SECRET_ACCESS_KEY=minioadmin

# For MinIO (development only)
AWS_ENDPOINT=http://minio:9000
AWS_FORCE_PATH_STYLE=true

# Local storage (alternative to S3)
LOCAL_STORAGE_PATH=./uploads

#-----------------------------------------------
# AI Service Implementation
#-----------------------------------------------
# Options: 'n8n', 'direct_llm'
AI_SERVICE_IMPLEMENTATION=n8n

#-----------------------------------------------
# N8N Integration (used when AI_SERVICE_IMPLEMENTATION=n8n)
#-----------------------------------------------
N8N_WEBHOOK_URL=http://n8n:5678
N8N_WEBHOOK_PATH=/webhook/customize-resume-ai
N8N_TIMEOUT_MS=120000
N8N_MAX_RETRIES=3

#-----------------------------------------------
# Direct LLM Integration (used when AI_SERVICE_IMPLEMENTATION=direct_llm)
#-----------------------------------------------
# LLM API Key (required for direct_llm implementation)
LLM_API_KEY=your-api-key-here
# Options: https://openrouter.ai/api, https://api.openai.com, etc.
LLM_API_BASE_URL=https://openrouter.ai/api
# Model name to use for LLM API
LLM_MODEL_NAME=deepseek/deepseek-r1-distill-llama-70b
# Timeout in milliseconds
LLM_TIMEOUT_MS=120000

#-----------------------------------------------
# Redis Configuration
#-----------------------------------------------
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_PASSWORD=  # Empty for development, set for production

#-----------------------------------------------
# Logging
#-----------------------------------------------
LOG_LEVEL=info  # debug, info, warn, error

#-----------------------------------------------
# Rate Limiting
#-----------------------------------------------
RATE_LIMIT_WINDOW_MS=900000  # 15 minutes
RATE_LIMIT_MAX=100  # 100 requests per windowMs

#-----------------------------------------------
# CORS Configuration
#-----------------------------------------------
CORS_ORIGIN=*  # Use specific domains in production
CORS_METHODS=GET,HEAD,PUT,PATCH,POST,DELETE
CORS_CREDENTIALS=false